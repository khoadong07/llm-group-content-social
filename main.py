import json
import fireworks.client

import streamlit as st
import pandas as pd
import time
import io
from dotenv import load_dotenv
import os

load_dotenv()

fireworks.client.api_key = os.getenv('FIREWORKS_API')

prompt = """
B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch ng√¥n ng·ªØ t·ª± nhi√™n, nhi·ªám v·ª• c·ªßa b·∫°n l√† ph√¢n t√≠ch c·∫£m x√∫c cho t·ª´ng comment d·ª±a tr√™n n·ªôi dung c·ªßa b√†i post. M·ªói comment s·∫Ω c√≥ m·ªôt ID duy nh·∫•t ƒë∆∞·ª£c cung c·∫•p t·ª´ input. B·∫°n c·∫ßn ph√¢n lo·∫°i c·∫£m x√∫c, x√°c ƒë·ªãnh c√°c t·ª´ kh√≥a ch√≠nh ·∫£nh h∆∞·ªüng ƒë·∫øn c·∫£m x√∫c ƒë√≥, tr√≠ch xu·∫•t th√¥ng tin v·ªÅ th∆∞∆°ng hi·ªáu, x√°c ƒë·ªãnh xem comment c√≥ ph·∫£i qu·∫£ng c√°o ho·∫∑c spam kh√¥ng, d·ª± ƒëo√°n nh√£n ng√†nh ngh·ªÅ (label), gi·∫£i th√≠ch √Ω ƒë·ªãnh (intent) v√† g√≥c nh√¨n (angle) c·ªßa comment.

**Sentiment labels:**
- POSITIVE: C·∫£m x√∫c t√≠ch c·ª±c.
- NEGATIVE: C·∫£m x√∫c ti√™u c·ª±c.
- NEUTRAL: C·∫£m x√∫c trung l·∫≠p, kh√¥ng r√µ r√†ng.
- MIXED: N·∫øu m·ªôt comment ch·ª©a c·∫£ hai lo·∫°i c·∫£m x√∫c, t√≠ch c·ª±c v√† ti√™u c·ª±c.

**Additional Tasks:**
1. **T·ª´ kh√≥a (keyword)**: Ph·∫£i l√† m·ªôt t√≠nh t·ª´ m√¥ t·∫£ c·∫£m x√∫c trong comment, kh√¥ng ch·ª©a t√™n ri√™ng ho·∫∑c brand attribute.
2. **Brand attribute**: N·∫øu trong comment c√≥ nh·∫Øc ƒë·∫øn th∆∞∆°ng hi·ªáu (brand), h√£y tr√≠ch xu·∫•t v√† th√™m tr∆∞·ªùng "brand attribute" ch·ª©a danh s√°ch c√°c th∆∞∆°ng hi·ªáu ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p. N·∫øu kh√¥ng c√≥ th∆∞∆°ng hi·ªáu n√†o ƒë∆∞·ª£c nh·∫Øc ƒë·∫øn, ƒë·ªÉ gi√° tr·ªã c·ªßa tr∆∞·ªùng n√†y l√† m·ªôt chu·ªói r·ªóng.
3. **Advertisement**: X√°c ƒë·ªãnh li·ªáu comment c√≥ ph·∫£i l√† qu·∫£ng c√°o kh√¥ng. Tr·∫£ v·ªÅ gi√° tr·ªã `advertisement: true/false`.
4. **Spam**: X√°c ƒë·ªãnh li·ªáu comment c√≥ ph·∫£i l√† spam kh√¥ng. Tr·∫£ v·ªÅ gi√° tr·ªã `spam: true/false`.
5. **Label**: D·ª± ƒëo√°n nh√£n ng√†nh ngh·ªÅ c·ªßa n·ªôi dung ƒëang ƒë·ªÅ c·∫≠p trong comment. Tr·∫£ v·ªÅ tr∆∞·ªùng `label`.
6. **Intent**: Gi·∫£i th√≠ch ng·∫Øn g·ªçn √Ω ƒë·ªãnh c·ªßa comment, tr·∫£ v·ªÅ tr∆∞·ªùng `intent`.
7. **Angle**: Gi·∫£i th√≠ch ng·∫Øn g·ªçn g√≥c nh√¨n (perspective) c·ªßa comment, tr·∫£ v·ªÅ tr∆∞·ªùng `angle`.

**Input format:**
{
  "post_content": "N·ªôi dung b√†i post c·∫ßn ph√¢n t√≠ch, l√† m·ªôt ƒëo·∫°n vƒÉn b·∫£n.",
  "comments": [
    {
      "id": "M√£ ƒë·ªãnh danh duy nh·∫•t c·ªßa comment.",
      "comment": "N·ªôi dung comment c·∫ßn ph√¢n t√≠ch, l√† m·ªôt ƒëo·∫°n vƒÉn b·∫£n ph·∫£n h·ªìi v·ªÅ b√†i post."
    }
  ]
}

**Task:**
1. ƒê·ªçc v√† ph√¢n t√≠ch n·ªôi dung b√†i post v√† t·ª´ng comment.
2. Ph√¢n lo·∫°i c·∫£m x√∫c c·ªßa m·ªói comment v√†o m·ªôt trong b·ªën nh√≥m: POSITIVE, NEGATIVE, NEUTRAL, ho·∫∑c MIXED.
3. X√°c ƒë·ªãnh c√°c t·ª´ kh√≥a ch√≠nh trong m·ªói comment ƒë√£ ·∫£nh h∆∞·ªüng ƒë·∫øn c·∫£m x√∫c. T·ª´ kh√≥a ph·∫£i l√† t√≠nh t·ª´ v√† kh√¥ng ch·ª©a t√™n ri√™ng ho·∫∑c brand attribute.
4. Tr√≠ch xu·∫•t th√¥ng tin th∆∞∆°ng hi·ªáu n·∫øu c√≥, n·∫øu kh√¥ng c√≥ th√¨ ƒë·∫∑t brand attribute l√† m·ªôt chu·ªói r·ªóng.
5. X√°c ƒë·ªãnh xem comment c√≥ ph·∫£i l√† qu·∫£ng c√°o (advertisement) hay kh√¥ng v√† tr·∫£ v·ªÅ `true/false`.
6. X√°c ƒë·ªãnh xem comment c√≥ ph·∫£i l√† spam hay kh√¥ng v√† tr·∫£ v·ªÅ `true/false`.
7. D·ª± ƒëo√°n nh√£n ng√†nh ngh·ªÅ (label) c·ªßa n·ªôi dung trong comment v√† tr·∫£ v·ªÅ tr∆∞·ªùng `label` s·ª≠ d·ª•ng ti·∫øng Vi·ªát.
8. Gi·∫£i th√≠ch ng·∫Øn g·ªçn √Ω ƒë·ªãnh c·ªßa comment v√† tr·∫£ v·ªÅ tr∆∞·ªùng `intent` s·ª≠ d·ª•ng ti·∫øng Vi·ªát.
9. Gi·∫£i th√≠ch ng·∫Øn g·ªçn g√≥c nh√¨n c·ªßa comment v√† tr·∫£ v·ªÅ tr∆∞·ªùng `angle` s·ª≠ d·ª•ng ti·∫øng Vi·ªát.
10. Tr·∫£ v·ªÅ k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng danh s√°ch JSON, trong ƒë√≥ m·ªói object ch·ª©a id, comment, ph√¢n lo·∫°i c·∫£m x√∫c, danh s√°ch t·ª´ kh√≥a, brand attribute, advertisement, spam, label, intent, v√† angle.

**Output format:**
[
  {
    "id": "M√£ ƒë·ªãnh danh duy nh·∫•t c·ªßa comment.",
    "comment": "N·ªôi dung comment.",
    "sentiment": "POSITIVE, NEGATIVE, NEUTRAL, ho·∫∑c MIXED",
    "keyword": [
      "Danh s√°ch c√°c t·ª´ kh√≥a ·∫£nh h∆∞·ªüng ƒë·∫øn c·∫£m x√∫c, l√† t√≠nh t·ª´ m√¥ t·∫£ c·∫£m x√∫c, kh√¥ng ch·ª©a t√™n ri√™ng ho·∫∑c brand."
    ],
    "brand_attribute": "Danh s√°ch c√°c th∆∞∆°ng hi·ªáu ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p (n·∫øu c√≥), n·∫øu kh√¥ng th√¨ ƒë·ªÉ chu·ªói r·ªóng.",
    "advertisement": "true/false",
    "spam": "true/false",
    "label": "Nh√£n ng√†nh ngh·ªÅ c·ªßa n·ªôi dung comment.",
    "intent": "Gi·∫£i th√≠ch ng·∫Øn g·ªçn √Ω ƒë·ªãnh c·ªßa comment.",
    "angle": "Gi·∫£i th√≠ch ng·∫Øn g·ªçn g√≥c nh√¨n c·ªßa comment."
  }
]

Ch·ªâ tr·∫£ v·ªÅ k·∫øt qu·∫£ theo format ```json kh√¥ng gi·∫£i th√≠ch g√¨ th√™m, ph√¢n t√≠ch d·ª±a tr√™n d·ªØ li·ªáu ƒë√£ cung c·∫•p, kh√¥ng s√°ng t·∫°o g√¨ th√™m
No yapping
"""

def extract_json_from_string(input_string):
    try:
        start_index = input_string.find("[")
        end_index = input_string.rfind("]") + 1

        json_string = input_string[start_index:end_index]

        json_data = json.loads(json_string)

        return json_data
    except json.JSONDecodeError as e:
        # print(input_string)

        # print(f"Error parsing JSON: {e}")
        return None


def group_comments_by_title(df):
    grouped_data = []
    for title, group in df.groupby('Title'):
        post_data = {
            "post_content": title,
            "comments": []
        }
        for _, row in group.iterrows():
            comment_data = {
                "id": row['Id'],
                "comment": row['Content']
            }
            post_data["comments"].append(comment_data)
        grouped_data.append(post_data)
    return grouped_data


def read_and_group_csv(df):
    """Read CSV file and group comments by title."""
    return group_comments_by_title(df)


def call_inference(post_data, prompt):
    """Call the Llama model for inference on post data."""
    completion = fireworks.client.ChatCompletion.create(
        "accounts/fireworks/models/llama-v3-70b-instruct",
        messages=[
            {"role": "system", "content": "B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch ng√¥n ng·ªØ t·ª± nhi√™n."},
            {"role": "user", "content": f"{prompt}\n\nInput: {str(post_data)}"}
        ],
        n=2,
        max_tokens=16000
    )
    result = completion.choices[0].message.content
    print(result)
    return extract_json_from_string(result)


def inference(grouped_comments, prompt):
    """Perform inference for each post and collect results."""
    results = []
    for post_data in grouped_comments:
        json_data = call_inference(post_data, prompt)
        if json_data:
            results.append(json_data)
    return results


def ensure_columns_exist(df, columns):
    """Ensure the specified columns exist in the DataFrame, creating them if necessary."""
    for field in columns:
        if field not in df.columns:
            df[field] = ""


def update_existing_rows(df, new_df):
    """Update existing rows in the DataFrame with new data from inference."""
    for index, row in new_df.iterrows():
        matching_rows = df[df['Id'] == row['id']]

        if not matching_rows.empty:
            df.loc[matching_rows.index, 'sentiment'] = row.get('sentiment', "")
            df.loc[matching_rows.index, 'keyword'] = ','.join(row.get('keyword', []))
            df.loc[matching_rows.index, 'brand_attribute'] = ','.join(row.get('brand_attribute', []))
            df.loc[matching_rows.index, 'advertisement'] = row.get('advertisement', "")
            df.loc[matching_rows.index, 'spam'] = row.get('spam', "")
            df.loc[matching_rows.index, 'label'] = row.get('label', "")
            df.loc[matching_rows.index, 'intent'] = row.get('intent', "")
            df.loc[matching_rows.index, 'angle'] = row.get('angle', "")
        else:
            new_row = {
                'Id': row['id'],
                'sentiment': row.get('sentiment', ""),
                'keyword': ','.join(row.get('keyword', [])),
                'brand_attribute': ','.join(row.get('brand_attribute', [])),
                'advertisement': row.get('advertisement', ""),
                'spam': row.get('spam', ""),
                'label': row.get('label', ""),
                'intent': row.get('intent', ""),
                'angle': row.get('angle', "")
            }
            df = df.append(new_row, ignore_index=True)
    return df


def merge_results_with_df(results, df_raw):
    """Merge inference results with CSV data and save to a new file."""

    flattened_results = [item for sublist in results for item in sublist]
    new_df = pd.DataFrame(flattened_results)
    expected_fields = ['sentiment', 'keyword', 'brand_attribute', 'advertisement', 'spam', 'label', 'intent', 'angle']
    ensure_columns_exist(df_raw, expected_fields)
    out_df = update_existing_rows(df_raw, new_df)
    out_df['spam'] = out_df['spam'].astype(bool)
    out_df['advertisement'] = out_df['advertisement'].astype(bool)
    out_df.loc[(out_df['spam'] == True) | (out_df['advertisement'] == True), 'sentiment'] = "NEUTRAL"
    return out_df


# Streamlit app
st.set_page_config(page_title="CSV/Excel Inference", page_icon="üìÑ", layout="wide")

# Title section with description
st.title("üìÑ Upload CSV/Excel and Perform Inference")
st.write("This app allows you to upload a CSV or Excel file, perform inference on the data, and display the results.")

# File upload section with styled file uploader
uploaded_file = st.file_uploader("üîÑ Choose a CSV or Excel file", type=["csv", "xlsx"])

# Processing the file if uploaded
if uploaded_file is not None:
    file_extension = uploaded_file.name.split('.')[-1]

    if file_extension == 'csv':
        df = pd.read_csv(uploaded_file)
    elif file_extension == 'xlsx':
        df = pd.read_excel(uploaded_file)

    # Check if necessary columns exist
    if not all(col in df.columns for col in ['Id', 'Title', 'Content', 'Type']):
        st.error("The file must contain `Id`, `Title`, `Content`, and `Type` columns.")
    else:
        st.success("File successfully uploaded! Below is a preview of the selected data.")

        # Data preview
        st.subheader("üîç Data Preview")
        df_selected = df[['Id', 'Title', 'Content', 'Type']]
        st.dataframe(df_selected.style.highlight_max(axis=0))

        # Divider for better structure
        st.markdown("---")

        # Add process button
        st.subheader("üöÄ Perform Inference")
        if st.button('Process Data'):
            with st.spinner('üîÑ Performing inference...'):
                # Simulate a delay for the processing
                time.sleep(2)
                grouped_comments = read_and_group_csv(df_selected)
                results = inference(grouped_comments, prompt)
                result_df = merge_results_with_df(results, df_selected)

                st.success("Inference completed!")

                # Show the resulting DataFrame
                st.subheader("üìä Inference Results")

                st.dataframe(result_df)

                # Divider for better structure
                st.markdown("---")

                # Provide an option to download the processed file
                st.subheader("üì• Download Processed Results")
                file_format = st.radio("Choose the format for download:", ('Excel', 'CSV'))


                if file_format == 'Excel':
                    processed_file_path = "processed_results.xlsx"
                    towrite = io.BytesIO()
                    result_df.to_excel(towrite, encoding='utf-8', index=False, engine='xlsxwriter')
                    towrite.seek(0)
                    st.download_button('Download Processed Excel', towrite, file_name='processed_results.xlsx',
                                       mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')

                elif file_format == 'CSV':
                    processed_file_path = "processed_results.csv"
                    result_df.to_csv(processed_file_path, index=False)
                    with open(processed_file_path, 'rb') as f:
                        st.download_button('Download Processed CSV', f, file_name='processed_results.csv')
# Footer
st.markdown("<br><hr style='border:1px solid #e6e6e6;'>", unsafe_allow_html=True)
# st.write("üí° Developed using [Streamlit](https://streamlit.io/) - Build beautiful apps with less effort.")